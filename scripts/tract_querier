#!/usr/bin/env python -O
from optparse import OptionParser
import os
import sys
import tract_querier



def main():
    parser = OptionParser(version=0.1, usage = "usage: %prog -t tractography_file -a atlas_file -q queries -o result_prefix")
    parser.add_option("-t", "--tractography", dest="tractography_file_name",
                    help="name of the tractography file")
    parser.add_option("-a", "--atlas", dest="atlas_file_name",
                    help="name of the atlas file")
    parser.add_option("-q", "--queries", dest="queries_string",
                    help="query to run")
    parser.add_option('-o', "--output", dest="output_file_name",
                    help="clustering output file prefix")
    parser.add_option('--threshold', dest='threshold', default=2,
                    help="Minimum percentage of the fiber to be considered inside of the label default %default %")
    parser.add_option('--length_threshold', dest='length_threshold', default=0,
                    help="Minimum length of the fiber to be considered (in mm) default %default %")


    (options, args) = parser.parse_args()

    if not options.tractography_file_name or\
       not options.atlas_file_name or\
       not options.queries_string or\
       not options.output_file_name:
        parser.error("incorrect number of arguments")

    options.threshold = float(options.threshold)
    options.length_threshold = float(options.length_threshold)

    import numpy as np
    import nibabel

    from tractographyGP import tractography

    print "Loading files"

    try:
        if os.path.exists(options.queries_string):
            query_file_body = tract_querier.queries_preprocess(file(options.queries_string).read(), filename=options.queries_string)
        else:
            query_file_body = tract_querier.queries_preprocess(options.queries_string, filename=options.queries_string)

        tract_querier.queries_syntax_check(query_file_body)
    except tract_querier.TractQuerierSyntaxError, e:
        parser.error(e.value)


    labels_nii = nibabel.load(options.atlas_file_name)
    img = labels_nii.get_data()

    tr = tractography.tractography_from_vtk_files(
        options.tractography_file_name
    )

    print "Calculating labels and crossings"
    affine = np.linalg.inv(labels_nii.get_affine())
    fibers = tr.getFibersToProcess()

    if options.length_threshold > 0:
        fiber_length = lambda fiber: ((((fiber[1:] - fiber[:-1]) ** 2).sum(1)) ** .5).sum()
        fibers = [f for f in fibers if fiber_length(f) >= options.length_threshold]

    all_points = np.vstack(fibers)
    all_points_ijk = (np.dot(affine[:-1, :-1], all_points.T).T +\
                      affine[:-1, -1])
    all_points_ijk_rounded = np.round(all_points_ijk).astype(int)

    if any( ((all_points_ijk_rounded[:, i] >= img.shape[i]).any() for i in xrange(3)))  or (all_points_ijk_rounded < 0).any():
        print >>sys.stderr, "Warning tract points fall outside the image"

    for i in xrange(3):
        all_points_ijk_rounded[:, i] = all_points_ijk_rounded[:, i].clip(0, img.shape[i] - 1)

    point_labels = img[tuple(all_points_ijk_rounded.T)]
    fiber_cumulative_lengths = np.cumsum([0] + [len(f) for f in fibers])

    fibers_labels = {}
    fibers_percentages = {}
    for i in xrange(len(fiber_cumulative_lengths) - 1):
        start = fiber_cumulative_lengths[i]
        end = fiber_cumulative_lengths[i + 1]
        label_crossings = np.asanyarray(point_labels[start:end], dtype=int)
        bincount = np.bincount(label_crossings)
        percentages = bincount * 1. / bincount.sum()
        fibers_labels[i] = set(np.where(percentages >= (float(options.threshold) / 100.))[0])

    labels_fibers = {}
    for i, f in fibers_labels.items():
        for l in f:
            if l in labels_fibers:
                labels_fibers[l].add(i)
            else:
                labels_fibers[l] = set((i,))

    print "Computing queries"
    evaluated_queries = tract_querier.eval_queries(labels_fibers, fibers_labels, query_file_body)


    query_names = evaluated_queries.keys()
    query_names.sort()

    for query_name in query_names:
        fiber_numbers = evaluated_queries[query_name]
        print "\tQuery %s: %.6d" % (query_name, len(fiber_numbers))
        if fiber_numbers:
            save_tractography_file(
                options.output_file_name + "_" + query_name + '.vtk',
                tr,
                fiber_numbers
            )

def save_tractography_file(filename, tractography, fiber_numbers):
    from tractographyGP import vtkInterface
    from itertools import izip
    import numpy as np

    fiber_numbers = list(fiber_numbers)

    original_fibers = tractography.getOriginalFibers()

    fibers_to_analyze_for_outlier_rejection = [original_fibers[i] for i in fiber_numbers]

    fiber_numbers_to_save, zscore_per_fiber = tract_querier.z_score_outlier_rejection(fibers_to_analyze_for_outlier_rejection)
    zscore_per_fiber.sort()
    print '\t', len(fiber_numbers_to_save)
    fiber_numbers = [ fiber_numbers[i] for i in fiber_numbers_to_save]
    fibers_to_save = [ original_fibers[i] for i in fiber_numbers]

    if len(fibers_to_save) == 0:
        return

    fibers_data_to_save = {}
    for key, data in tractography.getOriginalFibersData().items():
        fibers_data_to_save[key] = [data[f] for f in fiber_numbers]

    if 'ActiveTensors' not in fibers_data_to_save and 'Tensors_' in fibers_data_to_save:
        fibers_data_to_save['ActiveTensors'] = 'Tensors_'
    if 'ActiveVectors' not in fibers_data_to_save and 'Vectors_' in fibers_data_to_save:
        fibers_data_to_save['ActiveVectors'] = 'Vectors_'

    z_scores_fiber_data = [np.repeat(z_score, len(fiber))[:, None] for z_score, fiber in izip(zscore_per_fiber, fibers_to_save)]
    fibers_data_to_save['z_score'] = z_scores_fiber_data

    vtkInterface.writeLinesToVtkPolyData(
        filename,
        fibers_to_save,
        fibers_data_to_save
    )



if __name__ == "__main__":
    main()
    main()
